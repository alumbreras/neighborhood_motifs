install.packages('ggplot2', 'reshape2', 'dplyr', 'plyr', 'MASS', 'igraph')
install.packages('ggplot2')
install.packages('reshape2', "")
install.packages('reshape2')
install.packages("reshape2")
install.packages('plyr')
install.packages('dplyr')
setRepositories()
ap <- available.packages()
ap
View(ap)
"dplyr" %in% rownames(ap)
"MASS" %in% rownames(ap)
library(installr)
install.packages(installr)
install.packages('installr')
updateR()
gp
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/illustration_breakpoints.r')
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/illustration_order_neighbourhood.r')
library(igraph)
library(R.utils)
make_graph(1000)
?make_graph
erdos.renyi.game(100)
erdos.renyi.game(100, 2)
?erdos.renyi.game(100)
erdos.renyi.game(100, 0.75)
g <- erdos.renyi.game(100, 0.75)
is.iso <- withTimeout(is_isomorphic_to(g, g, method='vf2'), timeout = 10, onTimeout = "error")
is.iso
g2 <- erdos.renyi.game(100, 0.75)
is.iso <- withTimeout(is_isomorphic_to(g, g2, method='vf2'), timeout = 10, onTimeout = "error")
is.iso
sample(5)
sample(5,10)
sample(10,100)
sample(1000,100)
sample(1000,100, replace=TRUE)
sample(5,100, replace=TRUE)
g <- erdos.renyi.game(100, 0.75)
g2 <- erdos.renyi.game(100, 0.75)
g$color <- sample(5,100, replace=TRUE)
g2$color <- sample(5,100, replace=TRUE)
is.iso <- withTimeout(is_isomorphic_to(g, g2, method='vf2'), timeout = 10, onTimeout = "error")
is.iso
plot(g)
is.iso <- withTimeout(is_isomorphic_to(g, g, method='vf2'), timeout = 10, onTimeout = "error")
g$color
g
V(g)$color
g <- erdos.renyi.game(100, 0.75)
g2 <- erdos.renyi.game(100, 0.75)
V(g)$color <- sample(5,100, replace=TRUE)
V(g2)$color <- sample(5,100, replace=TRUE)
plot(g)
is.iso <- withTimeout(is_isomorphic_to(g, g, method='vf2'), timeout = 10, onTimeout = "error")
is.iso
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/timeout.r')
library(igraph)
library(R.utils)
N <- 10000
g <- erdos.renyi.game(N, 0.75)
V(g2)$color <- sample(5,N, replace=TRUE)
is.iso <- withTimeout(is_isomorphic_to(g, g, method='vf2'), timeout = 1, onTimeout = "error")
?withTimeout
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/timeout.r')
withTimeout(foo1(), timeout = 1, onTimeout = "warning")
withTimeout(foo2(), timeout = 1, onTimeout = "error")
withTimeout(foo1(), timeout = 1, onTimeout = "warning")
foo1 <- function() {
print("Tic");
for (kk in 1:100) {
print(kk);
Sys.sleep(0.3);
}
print("Tac");
}
withTimeout(foo1(), timeout = 1, onTimeout = "warning")
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
setwd("~/Documentos/PhD/src/neighborhood_motifs")
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
res.seq <- count_motifs_by_post(as.vector(unlist(chunks)),
database='reddit',
neighbourhood='struct')
chunks <- "t3_2bmb4v"
res.seq <- count_motifs_by_post(as.vector(unlist(chunks)),
database='reddit',
neighbourhood='struct')
warnings().
warnings()
is_isomorphic_to
graph.isomorphic.vf2
warnings()
c(1,2,3) == c(1,3,4)
all(c(1,2,3) == c(1,3,4))
any(c(1,2,3) == c(1,3,4))
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
res.seq <- count_motifs_by_post(as.vector(unlist(chunks)),
database='reddit',
neighbourhood='struct')
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
res.seq <- count_motifs_by_post(as.vector(unlist(chunks)),
database='reddit',
neighbourhood='struct')
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
res.seq <- count_motifs_by_post(as.vector(unlist(chunks)),
database='reddit',
neighbourhood='struct')
source('~/Documentos/PhD/src/neighborhood_motifs/R/count_motifs.r')
#https://www.reddit.com/r/catalunya
#https://www.reddit.com/r/es
library(parallel)
library(doParallel)
library(foreach)
library(ggplot2)
library(ggbiplot)
library(gplots)
library(dplyr)
library(reshape2)
library(igraph)
library(ggbiplot)
#library(RSQLite)
#library(GGally)
source('R/load_participations.r')
source('R/count_motifs.r')
source('R/normalize_counts.r')
source('R/clustering.r')
source('R/plotting.r')
##########################################################
# Load Data
##########################################################
load('./R_objects/dfposts_podemos.Rda')
df.posts$date <- as.numeric(df.posts$date)
df.posts <- data.frame(df.posts) %>% arrange(date)
df.posts <- df.posts[1:75000,] # Paper
df.threads <- plyr::count(df.posts, "thread")
df.users <- plyr::count(df.posts, 'user')
names(df.threads)[2] <- "length"
names(df.users)[2] <- "posts"
# Print dates range
start.date <- as.POSIXct(min(as.numeric(df.posts$date)), origin = "1970-01-01")
end.date <- as.POSIXct(max(as.numeric(df.posts$date)), origin = "1970-01-01")
print(paste("Start date:", start.date))
print(paste("End date:", end.date))
cat("Nunmber of posts:", nrow(df.posts))
cat('Number of threads: ', nrow(df.threads))
cat('Number of users: ', nrow(df.users))
cat('Number of active users', nrow(filter(df.users, posts>MIN_POSTS)))
MIN_POSTS <- 100
cat("Nunmber of posts:", nrow(df.posts))
cat('Number of threads: ', nrow(df.threads))
cat('Number of users: ', nrow(df.users))
cat('Number of active users', nrow(filter(df.users, posts>MIN_POSTS)))
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/70))
length(chunks)
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/1000))
length(chunks)
ncores <- detectCores() - 3
cl<-makeCluster(ncores, outfile="", port=11439)
registerDoParallel(cl)
pck <- c('RSQLite', 'data.table', 'changepoint')
res.parallel <- foreach(i=1:length(chunks), .packages = pck)%dopar%{
source('R/extract_from_db.r')
count_motifs_by_post(chunks[[i]],
database='reddit',
neighbourhood='struct', chunk.id=i)
}
stopCluster(cl)
res <- merge.motif.counts(res.parallel)
ls
res.parallel
