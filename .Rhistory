install.packages('ggplot2', 'reshape2', 'dplyr', 'plyr', 'MASS', 'igraph')
install.packages('ggplot2')
install.packages('reshape2', "")
install.packages('reshape2')
install.packages("reshape2")
install.packages('plyr')
install.packages('dplyr')
setRepositories()
ap <- available.packages()
ap
View(ap)
"dplyr" %in% rownames(ap)
"MASS" %in% rownames(ap)
library(installr)
install.packages(installr)
install.packages('installr')
updateR()
gp
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/illustration_breakpoints.r')
source('~/Documentos/PhD/src/neighborhood_motifs/sandbox/illustration_order_neighbourhood.r')
setwd("~/Documentos/PhD/src/neighborhood_motifs")
library(parallel)
library(doParallel)
library(foreach)
library(ggplot2)
library(ggbiplot)
library(gplots)
library(dplyr)
library(reshape2)
library(igraph)
library(ggbiplot)
#library(RSQLite)
#library(GGally)
source('R/load_participations.r')
source('R/count_motifs.r')
source('R/normalize_counts.r')
source('R/clustering.r')
MIN_POSTS <- 100 # number of post to consider a user as active
###################################################
# Load data
###################################################
#df.posts <- load_posts(database='reddit', forum='podemos')
#save(df.posts,file="dfposts.Rda")
#load('dfposts.Rda') # 836119 posts, 47803 threads
#df.posts <- load_posts(database='reddit', forum='gameofthrones')
#save(df.posts,file="dfposts.Rda")
load('./R_objects/dfposts_podemos.Rda')
df.posts$date <- as.numeric(df.posts$date)
df.posts <- data.frame(df.posts) %>% arrange(date)
df.posts <- df.posts[1:75000,] # Paper
#df.posts <- df.posts[1:5000,] # Debug
df.threads <- plyr::count(df.posts, "thread")
df.users <- plyr::count(df.posts, 'user')
names(df.threads)[2] <- "length"
names(df.users)[2] <- "posts"
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/300))
length(chunks)
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/500))
length(chunks)
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/750))
length(chunks)
# Profiling
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/800))
length(chunks)
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/900))
length(chunks)
chunks <- split(df.threads$thread, ceiling(seq_along(df.threads$thread)/1000))
length(chunks)
ncores <- detectCores() - 3
cl<-makeCluster(ncores, outfile="", port=11439)
registerDoParallel(cl)
pck <- c('RSQLite', 'data.table', 'changepoint')
res.parallel <- foreach(i=1:length(chunks), .packages = pck)%dopar%{
source('R/extract_from_db.r')
#withTimeout(  count_motifs_by_post(chunks[[i]],
#                                   database='reddit',
#                                   neighbourhood='time'),
#                                  120, onTimeout='warning')
count_motifs_by_post(chunks[[i]],
database='reddit',
neighbourhood='struct')
}
